{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "[Notebook Workflow Step-by-Step for CTX](#notebook-workflow-step-by-step-for-ctx)\n",
    "\n",
    "[Setup variables and configs](#setup-variables-and-configs)\n",
    "\n",
    "1. [1. Download images](#1-download-images)\n",
    "    - [Preview left and right image](#preview-left-and-right-image)\n",
    "2. [2. First Step of CTX processing lev1eo](#2-first-step-of-ctx-processing-lev1eo)\n",
    "3. [3. Metadata init](#3-metadata-init)\n",
    "    - [3.1. Stereo Quality Report](#31-stereo-quality-report)\n",
    "    - [Downsample images if requested](#downsample-images-if-requested)\n",
    "4. [4. Bundle adjustment](#4-bundle-adjustment)\n",
    "5. [5. Stereo first run (steps 1-3 of stereo in ASP)](#5-stereo-first-run-steps-1-3-of-stereo-in-asp)\n",
    "6. [6. Stereo first run (step 4 of stereo in ASP)](#6-stereo-first-run-step-4-of-stereo-in-asp)\n",
    "7. [7. Produce low resolution DEM for map projection](#7-produce-low-resolution-dem-for-map-projection)\n",
    "8. [8. Make GoodPixelMap and Hillshade Previews](#8-make-goodpixelmap-and-hillshade-previews)\n",
    "    - [Good Pixel Map](#good-pixel-map)\n",
    "    - [Hillshade of low res DEM](#hillshade-of-low-res-dem)\n",
    "9. [9. Mapproject ctx against 100m DEM](#9-mapproject-ctx-against-100m-dem)\n",
    "10. [10. Calculate Better DEM using prior](#10-calculate-better-dem-using-prior)\n",
    "11. [11. PC alignment (Step 5)](#11-pc-alignment-step-5)\n",
    "    - [Good Pixel Preview](#good-pixel-preview)\n",
    "    - [Hillshade of higher res DEM](#hillshade-of-higher-res-dem)\n",
    "    - [Show pedr data](#show-pedr-data)\n",
    "12. [12. Start of PC align portion](#12-start-of-pc-align-portion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Notebook Workflow Step-by-Step for CTX\n",
    "\n",
    "Now that we have run the Jupyter Notebook based workflows through the command line interface, we can look at each step that was run and describe what happened in more detail. Note that the function docstrings are also available to describe the parameters of a given step, and what that step does. Below is an export of all the codeblocks in the notebook workflow, additional markdown cells are included in the files but are not important to reproduce here. This workflow replicates the same workflow used by the asp_scripts project.\n",
    "\n",
    "First define all the parameters for the notebook for papermill. The notebook includes a cell metadata tag for papermill to allow these parameters to be defined at runtime. First we need the left and right image ids, the left image typically has the lower emission angle. ASAP will check the metadata of the images to ensure the correct order is provided. The config1 and config2 parameters are paths to stereo.default files the user has to configure the Ames Stereo Pipeline. The first config file is the only required parameter, config2 gives you to use higher quality parameters for the 2nd pass CTX DEM. The “dem_gsd” and “img_gsd” parameters control the number of pixels per pixel the final DEM and orthorectified images have. These default to 24 and 6 meters per pixel which works for generally any CTX image pair.\n",
    "\n",
    "Generally, most CTX images are captured at around 5.5 meters per pixel (GSD) so we pick 6 mpp as a reasonable default. By convention, the DEM post spacing should be at least 3X the image GSD. ASAP defaults to 4X the image GSD to be a bit more conservative, resulting in 24 meters per pixel. Output_path is typically left blank to default to the current working directory. The maxdisp parameter controls the maximum expected disparity (distance) between the intermediate CTX DEM and the reference topography. Leaving this as ‘None’ will allow ASAP to estimate the disparity for you. The downsample parameter allows you to downsample the imagery by a factor of the value to reduce processing times, a downsample of 4 will reduce the number of pixels by a factor of 4. The pedr_list variable points to the local copy of a file containing a list of all the paths to all of the MOLA PEDR data. By default this is set to None to use the ODE REST API to grab the necessary PEDR data, which is much faster anyways.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup variables and configs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from src.asp_wrapper import AmesPipelineWrapper\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup the parameters for the notebook\n",
    "\n",
    "# left, right = 'G03_019456_1646', 'G04_019601_1646'\n",
    "# left, right = 'K10_057105_1975', 'B08_012627_1975'\n",
    "# left, right = 'J16_050973_2046', 'N14_068038_2046'\n",
    "left, right='P20_008788_2067', 'P21_009355_2066'\n",
    "# left  = 'K14_059010_0916'\n",
    "\n",
    "# right = 'U15_076642_0916'\n",
    "\n",
    "# left = 'P02_001981_1823'\n",
    "# right = 'P03_002258_1817'\n",
    "config1 = None\n",
    "config2 = None\n",
    "dem_gsd  = 24.0\n",
    "img_gsd  = 6.0\n",
    "output_path = None\n",
    "max_disp = None\n",
    "downsample = None\n",
    "refdem = None\n",
    "step_kwargs = {}\n",
    "# todo: add reference_dem and use to conditional pedr things"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from IPython.display import Image\n",
    "from pathlib import Path\n",
    "from src.ctx import CTX\n",
    "from src.moody import ODE\n",
    "import math\n",
    "import os\n",
    "\n",
    "# default_output_dir = os.path.join(os.getcwd(), 'output')\n",
    "\n",
    "default_output_dir = \"/home/ivan/output/\"\n",
    "# Initialize the ODE and CTX classes\n",
    "ctx = CTX()\n",
    "ode = ODE(https=True)\n",
    "asp = AmesPipelineWrapper()\n",
    "\n",
    "# Reassign left and right to the correct order\n",
    "left, right = ctx.get_ctx_order(left, right)\n",
    "\n",
    "output_path = os.path.join(default_output_dir, f'a_{left}_{right}/') if not output_path else output_path\n",
    "print(\"Output directory: \", output_path)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "print(\"Left image PID:  %s\\nRight image PID: %s\" % (left, right))\n",
    "print(Path(output_path).absolute())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'Left image PID: {left}')\n",
    "data = ode.get_ctx_meta(left)\n",
    "# print(ode.get_ctx_meta(left))\n",
    "print(f\"Center longitude: {-360 + float(data['Center_longitude'])}\")\n",
    "print(f\"Center latitude: {data['Center_latitude']}\")\n",
    "\n",
    "print(f'Right image PID: {right}')\n",
    "data = ode.get_ctx_meta(right)\n",
    "# print(ode.get_ctx_meta(left))\n",
    "print(f\"Center longitude: {-360 + float(data['Center_longitude'])}\")\n",
    "print(f\"Center latitude: {data['Center_latitude']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Download images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are getting to the heart of the notebook workflow. First use step-one to download our left and right images using the moody tool. At the end of the command you can see we are using standard bash to redirect stdout and stderr to two log files, the first a log just for this step, the second a cumulative log file for the whole job.\n",
    "\n",
    "`asap ctx step_1 {left} {right} 2>&1 | tee -i -a ./1_download.log ./full_log.log`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Download the left and right images using moody\n",
    "\n",
    "# ctx.step_1()\n",
    "# ctx.generate_ctx_pair_list(left, right)\n",
    "left_id = ctx.get_full_ctx_id(left)\n",
    "right_id = ctx.get_full_ctx_id(right)\n",
    "# download files\n",
    "left_path = ode.download_ctx_edr(left_id, output_path)\n",
    "right_path = ode.download_ctx_edr(right_id, output_path)\n",
    "\n",
    "left_stem = os.path.join(os.path.dirname(left_path), f'{left_id}')\n",
    "right_stem = os.path.join(os.path.dirname(right_path), f'{right_id}')\n",
    "\n",
    "asp.setup_pair_info(output_path, left_stem, right_stem)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. First Step of CTX processing lev1eo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we replicate the preprocessing from the asp_scripts project/ames stereo pipeline using ISIS commands. This step will run these steps in the following order:\n",
    "\n",
    "1) `mroctx2isis`\n",
    "2) `spiceinit`\n",
    "3) `spicefit`\n",
    "4) `ctxcal`\n",
    "5) `ctxevenodd`\n",
    "\n",
    "`$ asap ctx step_2 {asap.kwarg_parse(step_kwargs, 'step_2')} 2>&1 | tee -i -a ./2_ctxedr2lev1eo.log ./full_log.log`\n",
    "\n",
    "Для корректной работы команд необходимо предзагрузить IsisData отсюда: https://astrogeology.usgs.gov/docs/how-to-guides/environment-setup-and-maintenance/isis-data-area/\n",
    "\n",
    "Т.к. работаем с миссей Mars Reconnaissance Orbiter, нужно ввести `downloadIsisData mro $ISISDATA`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from src.utils.common import run_parallel, rich_logger\n",
    "\n",
    "\n",
    "# @rich_logger\n",
    "# def step_2(ctx_wrapper: CTX, with_web=False):\n",
    "#     \"\"\"\n",
    "#     ISIS3 CTX preprocessing, replaces ctxedr2lev1eo.sh\n",
    "#\n",
    "#     :param with_web: if true attempt to use webservices for SPICE kernel data\n",
    "#     \"\"\"\n",
    "files = [output_path + left_id, output_path + right_id]\n",
    "run_parallel(asp.mroctx2isis, [f'from={i}.IMG to={i}.cub' for i in files], )\n",
    "\n",
    "run_parallel(asp.spiceinit, [f'from={i}.cub web=yes' for i in files])\n",
    "\n",
    "run_parallel(asp.spicefit, [f'from={i}.cub' for i in files])\n",
    "#\n",
    "run_parallel(asp.ctxcal, [f'from={i}.cub to={i}.lev1.cub' for i in files])\n",
    "\n",
    "# for cub in cubs:\n",
    "#     cub.unlink()\n",
    "\n",
    "\"\"\"\n",
    "**USER ERROR** The CTX image [/mnt/c/Users/Ivan/Documents/PROJECTS/Python/pyameslib/notebooks/output/a_N13_067270_0910_N12_067124_0910/N13_067270_0910_XN_89S005W.lev1.cub] has already been radiometrically calibrated.\n",
    "\"\"\"\n",
    "# lev1cubs = list(Path(output_path).glob('*.lev1.cub'))\n",
    "\n",
    "run_parallel(asp.ctxevenodd, [f'from={i}.lev1.cub to={i}.lev1.eo.cub' for i in files])\n",
    "# for lc in lev1cubs:\n",
    "#     lc.unlink()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!ls {output_path}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Metadata init\n",
    "\n",
    "Now we create a number of metadata files used by the asp_scripts project to simplify future command calls. We also copy our preprocessed CTX cub files into a new working directory where all the stereo products will be computed. This new directory name uses both image IDs joined by an underscore ‘{left_id}_{right_id}’, for example: “B03_010644_1889_XN_08N001W_P02_001902_1889_XI_08N001W”.\n",
    "\n",
    "`$ asap ctx step_3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.1. Stereo Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Generate stereo quality\n",
    "\n",
    "qual_report = asp.get_stereo_quality_report(f'{output_path + left_id}.lev1.eo.cub', f'{output_path + right_id}.lev1.eo.cub')\n",
    "print(qual_report)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Downsample images if requested"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "if downsample:\n",
    "    true_img_gsd_left = asp.get_image_gsd(f'{left}_{right}/{left}.lev1eo.cub')\n",
    "    true_img_gsd_right = asp.get_image_gsd(f'{left}_{right}/{right}.lev1eo.cub')\n",
    "    # take conservative approach, pick worst image GSD\n",
    "    res_gsd = max(true_img_gsd_left, true_img_gsd_right)\n",
    "    # this is because rescale in ISIS does not update GSD in metadata\n",
    "    asp.rescale_and_overwrite(factor=downsample)\n",
    "    img_gsd = math.ceil(res_gsd)*downsample\n",
    "    dem_gsd = 4*img_gsd\n",
    "    print('new img gsd', img_gsd)\n",
    "    print('new dem gsd', dem_gsd)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!gdal_translate -of GTiff -co COMPRESS=LZW {left_stem}.lev1.eo.cub {left_stem}.tif\n",
    "!gdal_translate -of GTiff -co COMPRESS=LZW {right_stem}.lev1.eo.cub {right_stem}.tif"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Bundle adjustment\n",
    "\n",
    "We will use the parallel_bundle_adjust command from Ames Stereo Pipeline to refine the spacecraft position and orientation. The user can later re-run this step with more advanced options or GCPs if so desired.\n",
    "\n",
    "`!asap ctx step_4 {asap.kwarg_parse(step_kwargs, 'step_4')} 2>&1 | tee -i -a ./2_bundle_adjust.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\"\"\"\n",
    "Bundle Adjust CTX\n",
    "\n",
    "Run bundle adjustment on the CTX map projected data\n",
    "\n",
    ":param vargs: variable length additional positional arguments to pass to bundle adjust\n",
    ":param bundle_adjust_prefix: prefix for bundle adjust output\n",
    ":param postfix: postfix for cub files to use\n",
    ":param camera_postfix: postfix for cameras\n",
    "\"\"\"\n",
    "asp.bundle_adjust(\n",
    "    bundle_adjust_prefix='adjust/ba',\n",
    "    postfix='.lev1.eo.cub',\n",
    "    camera_postfix='.lev1.eo.json'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preview"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!gdal_translate -of GTiff {left_stem}.lev1.eo.cub {left_stem}.tif -co COMPRESS=LZW\n",
    "!gdal_translate -of GTiff {right_stem}.lev1.eo.cub {right_stem}.tif -co COMPRESS=LZW"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show matplotlib previews\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=400)\n",
    "\n",
    "with rasterio.open(f'{left_stem}.tif', 'r') as src:\n",
    "    data = src.read(1)\n",
    "    img1 = ax1.imshow(src.read(1), cmap='gray', vmin=np.min(data), vmax=np.max(data))\n",
    "    ax1.set_xticks([])  # Remove x-axis ticks\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_title(f'{left}.IMG')\n",
    "\n",
    "with rasterio.open(f'{right_stem}.tif', 'r') as src:\n",
    "    data = src.read(1)\n",
    "    img2 = ax2.imshow(data, cmap='gray', vmin=np.min(data), vmax=np.max(data))\n",
    "    ax2.set_xticks([])  # Remove x-axis ticks\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_title(f'{right}.IMG')\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Stereo first run (steps 1-3 of stereo in ASP)\n",
    "\n",
    "Now we can start making our first dem, we pass in the stereo config file to parallel_stereo. We split this into two parts (step 5 & 6) as we may want to run each part with slightly different parameters or give us a chance to inspect the outputs before the final step which can be long running. In the future Step 5 & & maybe reconfigured into the 4 sub-steps for further improvement to the workflow.\n",
    "\n",
    "`!asap ctx step_5 {config1} {asap.kwarg_parse(step_kwargs, 'step_5')} 2>&1 | tee -i -a ./3_lev1eo2dem.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\"\"\"\n",
    "Parallel Stereo Part 1\n",
    "\n",
    "Run first part of parallel_stereo asp_ctx_lev1eo2dem.sh\n",
    "\n",
    ":param postfix: postfix for cub files to use\n",
    ":param camera_postfix: postfix for cameras  # TODO: use .adjusted_state.json?\n",
    "\"\"\"\n",
    "# defaults_ps1 = {\n",
    "#     '--processes': _processes,\n",
    "#     '--threads-singleprocess': _threads_singleprocess,\n",
    "#     '--threads-multiprocess': _threads_multiprocess,\n",
    "#     '--stop-point': 5,\n",
    "#     '--bundle-adjust-prefix': 'adjust/ba'\n",
    "# }\n",
    "\n",
    "# asp.stereo_asap(cub_postfix='.lev1.eo.cub', cam_postfix='.lev1.eo.json', stop_point=5)\n",
    "print(asp.workdir)\n",
    "for step in range(0, 5):\n",
    "    print(f\"Running step {step} of stereo\")\n",
    "    # run the step\n",
    "    asp.stereo_asap(\n",
    "        cub_postfix='.lev1.eo.cub',\n",
    "        cam_postfix='.lev1.eo.json',\n",
    "        entry_point=step,\n",
    "        stop_point=step + 1,\n",
    "        run='results_raw',\n",
    "        output_file_prefix=\"${run}/out\",\n",
    "        stereo_algorithm='asp_mgm',\n",
    "        corr_memory_limit_mb=16384,\n",
    "    )\n",
    "# asp.stereo_asap(\n",
    "#     cub_postfix='.lev1.eo.cub',\n",
    "#     cam_postfix='.lev1.eo.json',\n",
    "#     entry_point=0,\n",
    "#     stop_point=5,\n",
    "#     # alignment_method='local_epipolar',\n",
    "#     stereo_algorithm='asp_mgm',\n",
    "#     # job_size_h=512,\n",
    "#     # job_size_w=512,\n",
    "#     # sgm_collar_size=128,\n",
    "#     corr_memory_limit_mb=16384\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Stereo first run (step 4 of stereo in ASP)\n",
    "\n",
    "Run step 4, see step 5 above for more information.\n",
    "\n",
    "`!asap ctx step_6 {config1} {asap.kwarg_parse(step_kwargs, 'step_6')}  2>&1 | tee -i -a ./3_lev1eo2dem.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Parallel Stereo Part 2\n",
    "#\n",
    "# Run second part of parallel_stereo, asp_ctx_lev1eo2dem.sh stereo is completed after this step\n",
    "#\n",
    "# :param postfix: postfix for cub files to use\n",
    "# :param camera_postfix: postfix for cameras  # TODO: use .adjusted_state.json?\n",
    "\n",
    "# defaults_ps2 = {\n",
    "    #     '--processes': _threads_singleprocess,  # use more cores for triangulation!\n",
    "    #     '--threads-singleprocess': _threads_singleprocess,\n",
    "    #     '--threads-multiprocess': _threads_multiprocess,\n",
    "    #     '--entry-point': 5,\n",
    "    #     '--bundle-adjust-prefix': 'adjust/ba'\n",
    "    # }\n",
    "\n",
    "# return self.cs.stereo_asap(stereo_conf, postfix=postfix, camera_postfix=camera_postfix,\n",
    "#                            posargs=posargs, **{**self.cs.defaults_ps2, **kwargs})\n",
    "asp.stereo_asap(cub_postfix='.lev1.eo.cub', cam_postfix='.lev1.eo.json', entry_point=5, stop_point=6, run='results_raw')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Produce low resolution DEM for map projection\n",
    "\n",
    "We have made a point cloud, but it is preliminary so we will use it to make a 100 mpp DEM to map-project the CTX images to, to produce a better 2nd pass DEM.\n",
    "\n",
    "\n",
    "`! asap ctx step_7 --mpp 100 --just_ortho False --dem_hole_fill_len 50 {asap.kwarg_parse(step_kwargs, 'step_7')} 2>&1 | tee -i -a ./4_make_100m_dem.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Produce preview DEMs/Orthos\n",
    "\n",
    "Produce dem from point cloud, by default 24mpp for ctx for max-disparity estimation\n",
    "\n",
    ":param run: folder for results\n",
    ":param just_ortho: set to True if you only want the ortho image, else make dem and error image\n",
    ":param mpp: resolution in meters per pixel\n",
    ":param postfix: postfix for cub files to use\n",
    "\"\"\"\n",
    "# return self.cs.point_to_dem(mpp, 'PC.tif',\n",
    "#                             just_ortho=just_ortho,\n",
    "#                             postfix=postfix,\n",
    "#                             run=run,\n",
    "#                             kind='ba',\n",
    "#                             use_proj=self.proj,\n",
    "#                             **kwargs)\n",
    "asp.point_to_dem(100, 'PC.tif', just_ortho=False, run='results_raw', dem_hole_fill_len = 50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make GoodPixelMap and Hillshade Previews\n",
    "We make image previews of the DEM using the next few steps to check for issues with our first pass DEM. First we will render out the good pixel map image and then the hillshade of the DEM to look for issues with the topography.\n",
    "\n",
    "`!asap ctx step-8`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\"\"\"\n",
    "hillshade First step in asp_ctx_step2_map2dem script\n",
    "\n",
    ":param output_folder:\n",
    ":param run:\n",
    "\"\"\"\n",
    "_left_img, _right_img = asp._get_pair()\n",
    "dem_workdir = asp.stereo_pair.workdir + 'dem/'\n",
    "dem: Path = next(Path(dem_workdir).glob('*DEM.tif'))\n",
    "asp.hillshade(dem.absolute(), f'{dem_workdir}/{dem.stem}-hillshade.tif')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Good Pixel Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use some python to specify a new file name for the png version"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# both = f'{left}_{right}'\n",
    "img = f'{asp.stereo_pair.workdir}/results/out-GoodPixelMap.tif'\n",
    "out = img.replace('.tif', '.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use gdal_translate to produce a png version of the hillshade image."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!gdal_translate -of PNG -co worldfile=yes {img} {out}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hillshade of low res DEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now again for the hillshade"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# both = f'{left}_{right}'\n",
    "img = f'{dem_workdir}/{dem.stem}-hillshade.tif'\n",
    "out = img.replace('.tif', '.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to a png file again."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!gdal_translate -of PNG -co worldfile=yes {img} {out}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the image in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "\n",
    "# Пути к вашим GeoTIFF-файлам\n",
    "# img1_path = 'путь_к_первому_изображению.tif'\n",
    "# img2_path = 'путь_ко_второму_изображению.tif'\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "with rasterio.open(asp.stereo_pair.workdir + 'results_raw/out-GoodPixelMap.tif') as src1:\n",
    "    ax1.imshow(src1.read(1))\n",
    "    ax1.set_title('Good Pixel Map')\n",
    "    ax1.axis('off')\n",
    "\n",
    "with rasterio.open(dem_workdir + f'/{dem.stem}-hillshade.tif') as src2:\n",
    "    ax2.imshow(src2.read(1), cmap='gray')\n",
    "    ax2.set_title('Hillshade')\n",
    "    ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8. Mapproject ctx against 100m DEM\n",
    "\n",
    "We now map-project our ctx images against our low resolution DEM to reduce image distortion for our 2nd pass DEM.\n",
    "\n",
    "`!asap ctx step_9 --mpp {img_gsd} {asap.kwarg_parse(step_kwargs, 'step_9')} 2>&1 | tee -i -a ./5_mapproject_to_100m_dem.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\"\"\"\"\n",
    "Mapproject the left and right ctx images against the reference DEM\n",
    "\n",
    ":param run: name of run\n",
    ":param refdem: reference dem to map project using\n",
    ":param mpp: target GSD\n",
    ":param postfix: postfix for cub files to use\n",
    ":param camera_postfix: postfix for cameras to use\n",
    "\"\"\"\n",
    "asp.mapproject_both(ref_dem=dem.absolute(), mpp=img_gsd, bundle_adjust_prefix='adjust/ba')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 9. Calculate Better DEM using prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as step 5, just using the new map projected images this time.\n",
    "\n",
    "`!asap ctx step_10 {config2} {asap.kwarg_parse(step_kwargs, 'step_10')} 2>&1 | tee -i -a ./6_next_level_dem.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "asp.stereo_asap(\n",
    "    run='results_map_ba',\n",
    "    cub_postfix='.ba.map.tif',\n",
    "    cam_postfix='.lev1.eo.json',\n",
    "    ref_dem=dem.absolute(),\n",
    "    entry_point=0,\n",
    "    stop_point=5,\n",
    "    stereo_algorithm='asp_mgm',\n",
    "    subpixel_mode=3,\n",
    "    corr_memory_limit_mb=16384,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as step 6, just using the new map projected images this time.\n",
    "\n",
    "`!asap ctx step_11 {config2} {asap.kwarg_parse(step_kwargs, 'step_11')} 2>&1 | tee -i -a ./6_next_level_dem.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "asp.stereo_asap(\n",
    "    run='results_map_ba',\n",
    "    cub_postfix='.ba.map.tif',\n",
    "    cam_postfix='.lev1.eo.json',\n",
    "    ref_dem=dem.absolute(),\n",
    "    entry_point=5,\n",
    "    stop_point=6,\n",
    "    stereo_algorithm='asp_mgm',\n",
    "    subpixel_mode=3,\n",
    "    corr_memory_limit_mb=16384,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made our second point cloud, so we should export some visuals as before. The parameter ‘–folder’ just specifies that we are saving things into a different directory this time around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`!asap ctx step_7 --mpp {dem_gsd} --run results_map_ba {asap.kwarg_parse(step_kwargs, 'step_7_2')}`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "asp.point_to_dem(24, 'PC.tif', run='results_map_ba')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`!asap ctx step_8 --run results_map_ba`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "_left_img, _right_img = asp._get_pair()\n",
    "dem_workdir = asp.stereo_pair.workdir + 'dem/'\n",
    "dem: Path = next(Path(dem_workdir).glob('*24_0-DEM.tif'))\n",
    "asp.hillshade(dem.absolute(), f'{dem_workdir}/{dem.stem}-hillshade.tif')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Make Final GoodPixelMap and Hillshade Previews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Pixel Map\n",
    "\n",
    "\n",
    "Nothing too surprising here, just export PNG versions of the images we care about to see the DEM at this stage of the processing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "both = f'{left}_{right}'\n",
    "img = f'./{both}/results_map_ba/{both}_ba-GoodPixelMap.tif'\n",
    "out = img.replace('.tif', '.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!gdal_translate -of PNG -co worldfile=yes {img} {out}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Image(filename=out, width=800)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hillshade of higher res DEM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "both = f'{left}_{right}'\n",
    "img = './' + str(next(Path('../src/pyameslib/').glob(f'./{both}/results_map_ba/dem/{both}_ba_*-DEM-hillshade.tif')))\n",
    "out = img.replace('.tif', '.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!gdal_translate -of PNG -co worldfile=yes {img} {out}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Image(filename=out, width=600)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. PC alignment (Step 5)\n",
    "The final important step in the make_dem workflow is to get the MOLA PEDR data for the region we care about. Again, our data is not completely done until it has been aligned to the MOLA topography. If we had GCPs in the bundle adjust stage this would not be as big of an issue, but since it is relatively easy to align to MOLA we don’t need to go through the process of producing GCPs.\n",
    "\n",
    "There are two possibilities, either refdem is none (in which case get pedr data using moody) or we are given a dem\n",
    "currently this will always run even if refdem is provided, but below pc_align call will use refdem if it's not none\n",
    "\n",
    "`!asap ctx step_12 {refdem} 2>&1 | tee -i -a ./7_pedr_for_pc_align.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "asp.get_pedr_4_pcalign_w_moody(\n",
    "    cub_path=asp.stereo_pair.left + '.lev1.eo.cub',\n",
    "    proj=ctx.proj,\n",
    "    output_prefix=\"pedr4align\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Show pedr data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One additional bit here, for the MOLA data, show the PEDR2TAB template if created and the amount of PEDR data we have to align to. If the final line is less than a few hundred we could be in a bad situation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# !cat {asp.stereo_pair.workdir}PEDR2TAB.PRM\n",
    "import csv\n",
    "\n",
    "with open(asp.stereo_pair.workdir + 'pedr4align.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    pedr_data = list(reader)\n",
    "    print(f\"Number of PEDR data points: {len(pedr_data)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# !cat ./{left}_{right}/{left}_{right}_pedr4align.csv | wc -l"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished the first half of the workflow we can inspect the output products for issues before moving forwards. If there are issues noted in the log or after a particular step, that step can be re-run with different parameters until a good solution is found.\n",
    "\n",
    "At this point, we have a completed DEM! However, it’s absolute position in space maybe off from the correct position. Therefore, we must now perform a point cloud alignment to align our DEM with reference topography, in this case MOLA PEDR data to correct the position of the CTX DEM. In older versions of ASAP, this point is the dividing line between the make_dem and align_dem pipelines.\n",
    "\n",
    "The “maxdisp” parameter in particular deserves attention. It is the number passed to pc_align's –max-displacement parameter in the Ames Stereo Pipeline. Basically, it is the value of the distance you expect to move the CTX DEM to become aligned to your reference DEM (in this case, the PEDR data). It is generally worth estimating this number using a GIS to sample points in both the DEM and reference file, and seeing how far away they are from each other. But, CTX can be well-behaved with ASP, so we pick a default of 500 meters which can be large enough for many situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 12. Start of PC align portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align the DEM to MOLA\n",
    "\n",
    "This is the most important step in the 2nd half of the workflow as all the remaining steps are just producing final science products and visuals for the logs. This step runs pc_align using the provided max displacement (aka disparity). If the logs indicate a larger displacement was observed than the user provided value it will need to be re-run using larger values or with other advanced parameters. If users see issues it is generally easyier to re-run the pipeline at this step repeatedly in the command line or inside the Jupyter notebook.\n",
    "\n",
    "`!asap ctx step_13 --maxd {max_disp} --refdem {refdem} {asap.kwarg_parse(step_kwargs, 'step_13')} 2>&1 | tee -i -a ./8_pc_align.log ./full_log.log`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "asp.point_cloud_align(\n",
    "    datum=\"D_MARS\",\n",
    "    max_disparity=1000,\n",
    "    src_dem =asp.workdir +\"results_map_ba/out-PC.tif\",\n",
    "    ref_dem=asp.workdir + \"pedr4align.csv\",\n",
    "    kind='map_ba_align',\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the final CTX DEM\n",
    "\n",
    "After the previous step everything after is simple and easy as we now have a final aligned point cloud from which DEMs and ortho images can be made. That is all the rest of the steps do, they generate final DEMs with the geoid adjustment to produce science ready DEMs and ortho images for mapping.\n",
    "\n",
    "`!asap ctx step_14 --mpp {demgsd}  2>&1 | tee -i -a ./9_dems_orthos.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "asp.point_to_dem(\n",
    "    mpp=img_gsd,\n",
    "    pc_suffix = 'trans_reference.tif',\n",
    "    just_ortho=False,\n",
    "    run='pc_align',\n",
    "    kind='map_ba_aligned',\n",
    "    use_proj=ctx.proj,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust final CTX DEM to Geoid (Areoid)\n",
    "\n",
    "`!asap ctx step_15 2>&1 | tee -i -a ./10_geoid_adjustment.log  ./full_log.log`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "asp.geoid_adjust(\n",
    "    src_dem_sfx = \"6_0-DEM.tif\",\n",
    "    run = asp.workdir + \"dem\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the final CTX Hillshade and Orthos\n",
    "\n",
    "`!asap ctx step_8 --folder results_map_ba --output_folder dem_align 2>&1 | tee -i -a ./11_hillshade.log ./full_log.log`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "_left_img, _right_img = asp._get_pair()\n",
    "dem_workdir = asp.stereo_pair.workdir + 'dem/'\n",
    "dem: Path = next(Path(dem_workdir).glob('*6_0-DEM-geoid-adj.tif'))\n",
    "asp.hillshade(dem.absolute(), f'{dem_workdir}/{dem.stem}-hillshade.tif')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "img = f'{dem_workdir}/{dem.stem}-hillshade.tif'\n",
    "out = img.replace('.tif', '.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!gdal_translate -of PNG -co worldfile=yes {img} {out}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Image(filename=out, width=800)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`!asap ctx step_14 --mpp {img_gsd} --just_ortho True  2>&1 | tee -i -a ./12_img_full_ortho.log ./full_log.log`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "asp.point_to_dem(\n",
    "    mpp=img_gsd,\n",
    "    pc_suffix = 'out-PC.tif',\n",
    "    just_ortho=True,\n",
    "    run='results_map_ba',\n",
    "    kind='map_ba_aligned_ortho',\n",
    "    use_proj=ctx.proj,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
